{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1698382961805,
     "user": {
      "displayName": "Jason Kwok",
      "userId": "08535806470226027038"
     },
     "user_tz": 240
    },
    "id": "yrhxcF2eI3BP",
    "outputId": "86bf2479-4187-41ff-9f43-2aed5df4c175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "#@markdown Check type of GPU and VRAM available.\n",
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajcdBSMcJjGg"
   },
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4E3_MDCuPQGp"
   },
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!mkdir data/diagramatic-architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18846,
     "status": "ok",
     "timestamp": 1698383089235,
     "user": {
      "displayName": "Jason Kwok",
      "userId": "08535806470226027038"
     },
     "user_tz": 240
    },
    "id": "7AkNClgZRsDK",
    "outputId": "0049f216-9ae5-4ebb-c7dc-0048c346dda4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'diffusers'...\n",
      "remote: Enumerating objects: 41359, done.\u001b[K\n",
      "remote: Counting objects: 100% (1157/1157), done.\u001b[K\n",
      "remote: Compressing objects: 100% (573/573), done.\u001b[K\n",
      "remote: Total 41359 (delta 771), reused 794 (delta 490), pack-reused 40202\u001b[K\n",
      "Receiving objects: 100% (41359/41359), 27.49 MiB | 30.23 MiB/s, done.\n",
      "Resolving deltas: 100% (30577/30577), done.\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/diffusers.git\n",
    "%pip install -qq git+https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5220,
     "status": "ok",
     "timestamp": 1698379522849,
     "user": {
      "displayName": "Pandoks Online",
      "userId": "13599792785273051947"
     },
     "user_tz": 240
    },
    "id": "NezfD52XS3l5",
    "outputId": "0de29846-d9ba-45a0-820f-cb1850b45e54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18492,
     "status": "ok",
     "timestamp": 1698379640974,
     "user": {
      "displayName": "Pandoks Online",
      "userId": "13599792785273051947"
     },
     "user_tz": 240
    },
    "id": "6UoC0zMKI6Ut",
    "outputId": "e904ebef-4e93-49d5-be10-cc3066f0ef32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.22.post7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.23.5)\n",
      "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.1.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (4.8.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->xformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->xformers) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%pip install -q -U --pre triton\n",
    "%pip install -q accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors\n",
    "%pip install -U xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 95,
     "status": "ok",
     "timestamp": 1698383165280,
     "user": {
      "displayName": "Jason Kwok",
      "userId": "08535806470226027038"
     },
     "user_tz": 240
    },
    "id": "Vqqg03IBQjXf",
    "outputId": "cffa2b24-4317-4f0d-b706-d6b2c0e8c54e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/diffusers/examples\n"
     ]
    }
   ],
   "source": [
    "%cd diffusers/examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3plCOcEzJsLB"
   },
   "source": [
    "## Hugging Face Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3vQIFQyJG1X"
   },
   "outputs": [],
   "source": [
    "#@title Login to HuggingFace ðŸ¤—\n",
    "\n",
    "#@markdown You need to accept the model license before downloading or using the Stable Diffusion weights. Please, visit the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5), read the license and tick the checkbox if you agree. You have to be a registered user in ðŸ¤— Hugging Face Hub, and you'll also need to use an access token for the code to work.\n",
    "# https://huggingface.co/settings/tokens\n",
    "!mkdir -p ~/.huggingface\n",
    "HUGGINGFACE_TOKEN = \"\" #@param {type:\"string\"}\n",
    "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rF3YQTsYKCcB"
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15481,
     "status": "ok",
     "timestamp": 1698382984308,
     "user": {
      "displayName": "Jason Kwok",
      "userId": "08535806470226027038"
     },
     "user_tz": 240
    },
    "id": "d08PsvkcJ1Dh",
    "outputId": "0036ba2d-dc62-4102-98f8-2a3cea3b724b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "[*] Weights will be saved at /content/drive/MyDrive/Personal/Coding/Github\\ Projects/diagramatic-architecture/weights\n"
     ]
    }
   ],
   "source": [
    "#@markdown If model weights should be saved directly in google drive (takes around 4-5 GB).\n",
    "save_to_gdrive = True #@param {type:\"boolean\"}\n",
    "if save_to_gdrive:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "#@markdown Name/Path of the initial model.\n",
    "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Enter the directory name to save model at.\n",
    "\n",
    "OUTPUT_DIR = \"weights\" #@param {type:\"string\"}\n",
    "if save_to_gdrive:\n",
    "    OUTPUT_DIR = \"/content/drive/MyDrive/Personal/Coding/Github\\ Projects/diagramatic-architecture/\" + OUTPUT_DIR\n",
    "else:\n",
    "    OUTPUT_DIR = \"/content/\" + OUTPUT_DIR\n",
    "\n",
    "print(f\"[*] Weights will be saved at {OUTPUT_DIR}\")\n",
    "\n",
    "!mkdir -p $OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eA2bFRbnQkNg"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjIOgwRrP60d"
   },
   "source": [
    "Use the table below to choose the best flags based on your memory and speed requirements. Tested on Tesla T4 GPU.\n",
    "\n",
    "\n",
    "| `fp16` | `train_batch_size` | `gradient_accumulation_steps` | `gradient_checkpointing` | `use_8bit_adam` | GB VRAM usage | Speed (it/s) |\n",
    "| ---- | ------------------ | ----------------------------- | ----------------------- | --------------- | ---------- | ------------ |\n",
    "| fp16 | 1                  | 1                             | TRUE                    | TRUE            | 9.92       | 0.93         |\n",
    "| no   | 1                  | 1                             | TRUE                    | TRUE            | 10.08      | 0.42         |\n",
    "| fp16 | 2                  | 1                             | TRUE                    | TRUE            | 10.4       | 0.66         |\n",
    "| fp16 | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 1.14         |\n",
    "| no   | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 0.49         |\n",
    "| fp16 | 1                  | 2                             | TRUE                    | TRUE            | 11.56      | 1            |\n",
    "| fp16 | 2                  | 1                             | FALSE                   | TRUE            | 13.67      | 0.82         |\n",
    "| fp16 | 1                  | 2                             | FALSE                   | TRUE            | 13.7       | 0.83          |\n",
    "| fp16 | 1                  | 1                             | TRUE                    | FALSE           | 15.79      | 0.77         |\n",
    "*italicized text*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BIaGdFDQTm3"
   },
   "source": [
    "Add `--gradient_checkpointing` flag for around 9.92 GB VRAM usage.\n",
    "\n",
    "remove `--use_8bit_adam` flag for full precision. Requires 15.79 GB with `--gradient_checkpointing` else 17.8 GB.\n",
    "\n",
    "remove `--train_text_encoder` flag to reduce memory usage further, degrades output quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 976601,
     "status": "ok",
     "timestamp": 1698380673889,
     "user": {
      "displayName": "Pandoks Online",
      "userId": "13599792785273051947"
     },
     "user_tz": 240
    },
    "id": "xneoovikCWx7",
    "outputId": "07d400ee-cf36-4b78-c85c-b685a36c164f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.1.0+cu121 with CUDA 1201 (you have 2.1.0+cu118)\n",
      "    Python  3.10.13 (you have 3.10.12)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "2023-10-27 04:08:26.484788: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-27 04:08:26.484839: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-27 04:08:26.484873: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-27 04:08:27.620174: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "10/27/2023 04:08:28 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/pipeline_utils.py:268: FutureWarning: You are loading the variant fp16 from runwayml/stable-diffusion-v1-5 via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that runwayml/stable-diffusion-v1-5 currently does not have the required variant filenames in the 'main' branch. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'runwayml/stable-diffusion-v1-5 is missing fp16 files' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "Loading pipeline components...:  17% 1/6 [00:00<00:04,  1.10it/s]Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "Loading pipeline components...:  33% 2/6 [00:01<00:01,  2.05it/s]/usr/local/lib/python3.10/dist-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Loaded feature_extractor as CLIPFeatureExtractor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "{'conv_in_kernel', 'encoder_hid_dim_type', 'addition_time_embed_dim', 'time_embedding_dim', 'num_attention_heads', 'dropout', 'addition_embed_type', 'reverse_transformer_layers_per_block', 'encoder_hid_dim', 'time_cond_proj_dim', 'transformer_layers_per_block', 'use_linear_projection', 'class_embed_type', 'attention_type', 'mid_block_only_cross_attention', 'time_embedding_type', 'resnet_time_scale_shift', 'addition_embed_type_num_heads', 'time_embedding_act_fn', 'cross_attention_norm', 'conv_out_kernel', 'timestep_post_act', 'mid_block_type', 'only_cross_attention', 'projection_class_embeddings_input_dim', 'upcast_attention', 'num_class_embeds', 'dual_cross_attention', 'class_embeddings_concat', 'resnet_out_scale_factor', 'resnet_skip_time_act'} was not found in config. Values will be initialized to default values.\n",
      "Loaded unet as UNet2DConditionModel from `unet` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "Loading pipeline components...:  67% 4/6 [00:03<00:01,  1.07it/s]{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "Loading pipeline components...:  83% 5/6 [00:03<00:00,  1.48it/s]Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "Loading pipeline components...: 100% 6/6 [00:06<00:00,  1.04s/it]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "10/27/2023 04:08:36 - INFO - __main__ - Number of class images to sample: 42.\n",
      "Generating class images: 100% 11/11 [01:29<00:00,  8.11s/it]\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "Downloading (â€¦)cheduler_config.json: 100% 308/308 [00:00<00:00, 1.43MB/s]\n",
      "{'sample_max_value', 'clip_sample_range', 'thresholding', 'variance_type', 'timestep_spacing', 'prediction_type', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from runwayml/stable-diffusion-v1-5 via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that runwayml/stable-diffusion-v1-5 currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of runwayml/stable-diffusion-v1-5. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'runwayml/stable-diffusion-v1-5 is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from runwayml/stable-diffusion-v1-5 via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that runwayml/stable-diffusion-v1-5 currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of runwayml/stable-diffusion-v1-5. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'runwayml/stable-diffusion-v1-5 is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "{'conv_in_kernel', 'encoder_hid_dim_type', 'addition_time_embed_dim', 'time_embedding_dim', 'num_attention_heads', 'dropout', 'addition_embed_type', 'reverse_transformer_layers_per_block', 'encoder_hid_dim', 'time_cond_proj_dim', 'transformer_layers_per_block', 'use_linear_projection', 'class_embed_type', 'attention_type', 'mid_block_only_cross_attention', 'time_embedding_type', 'resnet_time_scale_shift', 'addition_embed_type_num_heads', 'time_embedding_act_fn', 'cross_attention_norm', 'conv_out_kernel', 'timestep_post_act', 'mid_block_type', 'only_cross_attention', 'projection_class_embeddings_input_dim', 'upcast_attention', 'num_class_embeds', 'dual_cross_attention', 'class_embeddings_concat', 'resnet_out_scale_factor', 'resnet_skip_time_act'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
      "================================================================================\n",
      "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:105: UserWarning: /usr/lib64-nvidia did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//172.28.0.1'), PosixPath('http'), PosixPath('8013')}\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-v100-s-25vvkuv8do34z --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages')}\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n",
      "  warn(\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118_nocublaslt.so...\n",
      "10/27/2023 04:10:29 - INFO - __main__ - ***** Running training *****\n",
      "10/27/2023 04:10:29 - INFO - __main__ -   Num examples = 140\n",
      "10/27/2023 04:10:29 - INFO - __main__ -   Num batches each epoch = 140\n",
      "10/27/2023 04:10:29 - INFO - __main__ -   Num Epochs = 8\n",
      "10/27/2023 04:10:29 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "10/27/2023 04:10:29 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "10/27/2023 04:10:29 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "10/27/2023 04:10:29 - INFO - __main__ -   Total optimization steps = 1000\n",
      "Steps:   0% 0/1000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Steps:  50% 500/1000 [04:52<05:42,  1.46it/s, loss=0.124, lr=1e-6]10/27/2023 04:15:22 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-500\n",
      "Configuration saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-500/unet/config.json\n",
      "Model weights saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-500/unet/diffusion_pytorch_model.safetensors\n",
      "10/27/2023 04:15:50 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-500/optimizer.bin\n",
      "10/27/2023 04:15:50 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-500/scheduler.bin\n",
      "10/27/2023 04:15:50 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-500/sampler.bin\n",
      "10/27/2023 04:15:50 - INFO - accelerate.checkpointing - Sampler state for dataloader 1 saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-500/sampler_1.bin\n",
      "10/27/2023 04:15:50 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-500/scaler.pt\n",
      "10/27/2023 04:15:50 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-500/random_states_0.pkl\n",
      "10/27/2023 04:15:50 - INFO - __main__ - Saved state to /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-500\n",
      "Steps: 100% 1000/1000 [10:38<00:00,  1.60it/s, loss=0.308, lr=1e-6]10/27/2023 04:21:08 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-1000\n",
      "Configuration saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-1000/unet/config.json\n",
      "Model weights saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-1000/unet/diffusion_pytorch_model.safetensors\n",
      "10/27/2023 04:22:03 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-1000/optimizer.bin\n",
      "10/27/2023 04:22:03 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-1000/scheduler.bin\n",
      "10/27/2023 04:22:03 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-1000/sampler.bin\n",
      "10/27/2023 04:22:03 - INFO - accelerate.checkpointing - Sampler state for dataloader 1 saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-1000/sampler_1.bin\n",
      "10/27/2023 04:22:03 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-1000/scaler.pt\n",
      "10/27/2023 04:22:03 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-1000/random_states_0.pkl\n",
      "10/27/2023 04:22:03 - INFO - __main__ - Saved state to /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/checkpoint-1000\n",
      "Steps: 100% 1000/1000 [11:33<00:00,  1.60it/s, loss=0.281, lr=1e-6]vae/diffusion_pytorch_model.safetensors not found\n",
      "\n",
      "Fetching 11 files:   0% 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Downloading (â€¦)_checker/config.json: 100% 4.70k/4.70k [00:00<00:00, 19.9MB/s]\n",
      "\n",
      "Fetching 11 files:  27% 3/11 [00:00<00:01,  5.91it/s]\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:   0% 0.00/608M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:   2% 10.5M/608M [00:00<00:18, 32.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:   5% 31.5M/608M [00:00<00:08, 69.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:   9% 52.4M/608M [00:00<00:05, 93.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  12% 73.4M/608M [00:00<00:05, 100MB/s] \u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  16% 94.4M/608M [00:00<00:04, 113MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  19% 115M/608M [00:01<00:03, 127MB/s] \u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  22% 136M/608M [00:01<00:03, 135MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  28% 168M/608M [00:01<00:02, 155MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  31% 189M/608M [00:01<00:02, 160MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  34% 210M/608M [00:01<00:02, 158MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  38% 231M/608M [00:01<00:02, 151MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  41% 252M/608M [00:01<00:02, 153MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  45% 273M/608M [00:02<00:02, 157MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  48% 294M/608M [00:02<00:02, 156MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  52% 315M/608M [00:02<00:01, 165MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  55% 336M/608M [00:02<00:01, 169MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  59% 357M/608M [00:02<00:01, 160MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  62% 377M/608M [00:02<00:01, 167MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  66% 398M/608M [00:02<00:01, 172MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  69% 419M/608M [00:02<00:01, 158MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  72% 440M/608M [00:05<00:07, 23.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  76% 461M/608M [00:06<00:07, 20.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  79% 482M/608M [00:07<00:04, 27.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  83% 503M/608M [00:07<00:02, 36.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  86% 524M/608M [00:07<00:02, 40.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  88% 535M/608M [00:07<00:01, 43.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  90% 545M/608M [00:07<00:01, 46.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  91% 556M/608M [00:08<00:01, 50.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  93% 566M/608M [00:08<00:00, 53.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  95% 577M/608M [00:08<00:00, 56.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  97% 587M/608M [00:08<00:00, 62.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  98% 598M/608M [00:08<00:00, 63.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin: 100% 608M/608M [00:08<00:00, 68.3MB/s]\n",
      "\n",
      "Fetching 11 files: 100% 11/11 [00:09<00:00,  1.14it/s]\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[A{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "\n",
      "Loading pipeline components...:  14% 1/7 [00:01<00:11,  1.95s/it]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "\n",
      "Loading pipeline components...:  29% 2/7 [00:02<00:05,  1.04s/it]\u001b[A`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "\n",
      "Loading pipeline components...:  43% 3/7 [00:06<00:10,  2.61s/it]\u001b[ALoaded feature_extractor as CLIPFeatureExtractor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "Loading pipeline components...: 100% 7/7 [00:06<00:00,  1.01it/s]\n",
      "{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "Configuration saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/vae/config.json\n",
      "Model weights saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/vae/diffusion_pytorch_model.safetensors\n",
      "Configuration saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/unet/config.json\n",
      "Model weights saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/unet/diffusion_pytorch_model.safetensors\n",
      "Configuration saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/scheduler/scheduler_config.json\n",
      "Configuration saved in /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/model_index.json\n",
      "Steps: 100% 1000/1000 [13:52<00:00,  1.20it/s, loss=0.281, lr=1e-6]\n"
     ]
    }
   ],
   "source": [
    "!python3 dreambooth/train_dreambooth.py \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "  --output_dir=$OUTPUT_DIR \\\n",
    "  --revision=\"fp16\" \\\n",
    "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
    "  --seed=1337 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --train_text_encoder \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --gradient_checkpointing \\\n",
    "  --use_8bit_adam \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --learning_rate=1e-6 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --num_class_images=50 \\\n",
    "  --sample_batch_size=4 \\\n",
    "  --max_train_steps=1000 \\\n",
    "  --instance_data_dir=\"/content/data/diagramatic-architecture\" \\\n",
    "  --instance_prompt=\"photo of diagramatic architecture\" \\\n",
    "  --class_data_dir=\"/content/data/diagram\" \\\n",
    "  --class_prompt=\"photo of a diagram\"\n",
    "\n",
    "# Reduce the `--save_interval` to lower than `--max_train_steps` to save weights from intermediate steps.\n",
    "# `--save_sample_prompt` can be same as `--instance_prompt` to generate intermediate samples (saved along with weights in samples directory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ce_QlafHY5F_"
   },
   "source": [
    "#Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2007,
     "status": "ok",
     "timestamp": 1698383562897,
     "user": {
      "displayName": "Jason Kwok",
      "userId": "08535806470226027038"
     },
     "user_tz": 240
    },
    "id": "txed7kWZZW-i",
    "outputId": "1c0c221f-1821-4ffe-eae2-3ab59cb5ad6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: convert_diffusers_to_original_stable_diffusion.py [-h] --model_path MODEL_PATH\n",
      "                                                         --checkpoint_path CHECKPOINT_PATH\n",
      "                                                         [--half] [--use_safetensors]\n",
      "convert_diffusers_to_original_stable_diffusion.py: error: unrecognized arguments: Projects/diagramatic-architecture/weights Projects/diagramatic-architecture/weights/model.ckpt\n",
      "[*] Converted ckpt saved at contents/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "#@markdown Run conversion.\n",
    "WEIGHTS_DIR = \"contents/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights\"\n",
    "ckpt_path = \"contents/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/model.ckpt\"\n",
    "\n",
    "half_arg = \"\"\n",
    "#@markdown  Whether to convert to fp16, takes half the space (2GB).\n",
    "fp16 = True #@param {type: \"boolean\"}\n",
    "if fp16:\n",
    "    half_arg = \"--half\"\n",
    "!python ../scripts/convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $ckpt_path $half_arg\n",
    "print(f\"[*] Converted ckpt saved at {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2758,
     "status": "ok",
     "timestamp": 1698383695051,
     "user": {
      "displayName": "Jason Kwok",
      "userId": "08535806470226027038"
     },
     "user_tz": 240
    },
    "id": "ZCawizxshuL3",
    "outputId": "643a6fbf-80d1-46c2-ffac-8a64506a9f41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/content/diffusers/examples/../scripts/convert_diffusers_to_original_stable_diffusion.py\", line 290, in <module>\n",
      "    unet_state_dict = torch.load(unet_path, map_location=\"cpu\")\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 986, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 435, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 416, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/unet/diffusion_pytorch_model.bin'\n",
      "[*] Converted ckpt saved at /content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "WEIGHTS_DIR = \"/content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights\"\n",
    "ckpt_path = \"/content/drive/MyDrive/Personal/Coding/Github Projects/diagramatic-architecture/weights/model.ckpt\"\n",
    "\n",
    "half_arg = \"\"\n",
    "fp16 = True\n",
    "if fp16:\n",
    "    half_arg = \"--half\"\n",
    "\n",
    "cmd = f\"python ../scripts/convert_diffusers_to_original_stable_diffusion.py --model_path '{WEIGHTS_DIR}' --checkpoint_path '{ckpt_path}' {half_arg}\"\n",
    "!{cmd}\n",
    "print(f\"[*] Converted ckpt saved at {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNkVjZgOi6UM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
